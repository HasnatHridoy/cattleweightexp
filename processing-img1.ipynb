{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":4929416,"sourceType":"datasetVersion","datasetId":2857519}],"dockerImageVersionId":30648,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install -q \\\nautodistill \\\nautodistill-yolov8 \\\nroboflow \\\nsupervision==0.9.0 \\\nautodistill-grounded-sam\n\n","metadata":{"execution":{"iopub.status.busy":"2024-02-04T05:16:08.039677Z","iopub.execute_input":"2024-02-04T05:16:08.040149Z","iopub.status.idle":"2024-02-04T05:16:29.750619Z","shell.execute_reply.started":"2024-02-04T05:16:08.040111Z","shell.execute_reply":"2024-02-04T05:16:29.749462Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\njupyterlab 4.0.11 requires jupyter-lsp>=2.0.0, but you have jupyter-lsp 1.5.1 which is incompatible.\njupyterlab-lsp 5.0.2 requires jupyter-lsp>=2.0.0, but you have jupyter-lsp 1.5.1 which is incompatible.\nlibpysal 4.9.2 requires packaging>=22, but you have packaging 21.3 which is incompatible.\nlibpysal 4.9.2 requires shapely>=2.0.1, but you have shapely 1.8.5.post1 which is incompatible.\nmomepy 0.7.0 requires shapely>=2, but you have shapely 1.8.5.post1 which is incompatible.\nosmnx 1.8.1 requires shapely>=2.0, but you have shapely 1.8.5.post1 which is incompatible.\nspopt 0.6.0 requires shapely>=2.0.1, but you have shapely 1.8.5.post1 which is incompatible.\ntensorflowjs 4.16.0 requires packaging~=23.1, but you have packaging 21.3 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0m","output_type":"stream"}]},{"cell_type":"markdown","source":"### In this notebook we have done image precessing and create a pipeline to train our model.","metadata":{}},{"cell_type":"code","source":"from autodistill.detection import CaptionOntology\nfrom autodistill_grounded_sam import GroundedSAM","metadata":{"execution":{"iopub.status.busy":"2024-02-04T05:16:33.335633Z","iopub.execute_input":"2024-02-04T05:16:33.335982Z","iopub.status.idle":"2024-02-04T05:16:42.143341Z","shell.execute_reply.started":"2024-02-04T05:16:33.335954Z","shell.execute_reply":"2024-02-04T05:16:42.142607Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"# copy specific number of picture for preprocessing\n\nimport shutil\nimport os\n\ndef copy_images_range(source_folder, destination_folder, start_index, end_index):\n    \n    if not os.path.exists(destination_folder):\n        os.makedirs(destination_folder)\n\n    files = os.listdir(source_folder)\n\n    files.sort()\n\n    if start_index >= len(files) or end_index >= len(files) or start_index > end_index:\n        print(\"Invalid indices provided. Please check the range.\")\n        return\n\n    \n    try:\n        for i in range(start_index, end_index):\n            source_path = os.path.join(source_folder, files[i])\n            destination_path = os.path.join(destination_folder, files[i])\n\n            shutil.copy2(source_path, destination_path)\n            \n        print(\"Copy successful.\")\n    except:\n        print(\"Copy failed.\")\n\nsource_folder = '/kaggle/input/cattle-weight-detection-model-dataset-12k/www.acmeai.tech Dataset - BMGF-LivestockWeight-CV/Pixel/B3/images'\ndestination_folder = '/kaggle/working/images'\nstart_index = 2400  \nend_index = 2500   \n\ncopy_images_range(source_folder, destination_folder, start_index, end_index)\n","metadata":{"execution":{"iopub.status.busy":"2024-02-04T05:36:19.309713Z","iopub.execute_input":"2024-02-04T05:36:19.310823Z","iopub.status.idle":"2024-02-04T05:36:22.110057Z","shell.execute_reply.started":"2024-02-04T05:36:19.310782Z","shell.execute_reply":"2024-02-04T05:36:22.109111Z"}},"execution_count":null,"outputs":[]},{"cell_type":"raw","source":"","metadata":{}},{"cell_type":"code","source":"!cd /kaggle/working/\nimport os\nHOME = os.getcwd()\nprint(HOME)\nIMAGE_DIR_PATH = f\"{HOME}/images\"\nDATASET_DIR_PATH = f\"{HOME}/dataset\"","metadata":{"execution":{"iopub.status.busy":"2024-02-04T05:36:28.222954Z","iopub.execute_input":"2024-02-04T05:36:28.223305Z","iopub.status.idle":"2024-02-04T05:36:29.262145Z","shell.execute_reply.started":"2024-02-04T05:36:28.223281Z","shell.execute_reply":"2024-02-04T05:36:29.260906Z"},"trusted":true},"execution_count":17,"outputs":[{"name":"stdout","text":"/kaggle/working\n","output_type":"stream"}]},{"cell_type":"code","source":"# preprocessing and labling\n\nBOX_THRESHOLD = 0.5\nTEXT_THRESHOLD = 0.70\n\n\nCAPTION_ONTOLOGY = {\n    \"a cow\": \"cow\",\n    \"a circle shape paper sticker\": \"sticker\"\n}\n\nmodel = GroundedSAM(\n    ontology=CaptionOntology(CAPTION_ONTOLOGY),\n    box_threshold=BOX_THRESHOLD,\n    text_threshold=TEXT_THRESHOLD,\n)\n\ndataset = model.label(\n    input_folder=IMAGE_DIR_PATH,\n    extension=\".jpg\",\n    output_folder=DATASET_DIR_PATH)","metadata":{"execution":{"iopub.status.busy":"2024-02-04T05:36:33.733033Z","iopub.execute_input":"2024-02-04T05:36:33.733420Z","iopub.status.idle":"2024-02-04T05:40:01.979271Z","shell.execute_reply.started":"2024-02-04T05:36:33.733390Z","shell.execute_reply":"2024-02-04T05:40:01.978225Z"},"trusted":true},"execution_count":18,"outputs":[{"name":"stdout","text":"trying to load grounding dino directly\nfinal text_encoder_type: bert-base-uncased\n","output_type":"stream"},{"name":"stderr","text":"Labeling /kaggle/working/images/76_s_172_F.jpg: 100%|██████████| 100/100 [03:10<00:00,  1.91s/it]\n","output_type":"stream"},{"name":"stdout","text":"Labeled dataset created - ready for distillation.\n","output_type":"stream"}]},{"cell_type":"code","source":"!rm -r /kaggle/working/images\n!rm -r /kaggle/working/dataset/images\n!rm -r /kaggle/working/dataset/annotations\n!cd /kaggle/working/dataset","metadata":{"execution":{"iopub.status.busy":"2024-02-04T05:40:06.375148Z","iopub.execute_input":"2024-02-04T05:40:06.375514Z","iopub.status.idle":"2024-02-04T05:40:10.743063Z","shell.execute_reply.started":"2024-02-04T05:40:06.375485Z","shell.execute_reply":"2024-02-04T05:40:10.741663Z"},"trusted":true},"execution_count":19,"outputs":[]},{"cell_type":"code","source":"import zipfile\nimport os\nfrom IPython.display import FileLink\n\ndef zip_dir(directory = os.curdir, file_name = 'directory.zip'):\n    \n    os.chdir(directory)\n    zip_ref = zipfile.ZipFile(file_name, mode='w')\n    for folder, _, files in os.walk(directory):\n        for file in files:\n            if file_name in file:\n                pass\n            else:\n                zip_ref.write(os.path.join(folder, file))\n\n    return FileLink(file_name)\n\nzip_dir()","metadata":{"execution":{"iopub.status.busy":"2024-02-04T05:40:27.407422Z","iopub.execute_input":"2024-02-04T05:40:27.408446Z","iopub.status.idle":"2024-02-04T05:40:27.786982Z","shell.execute_reply.started":"2024-02-04T05:40:27.408404Z","shell.execute_reply":"2024-02-04T05:40:27.786026Z"},"trusted":true},"execution_count":21,"outputs":[{"execution_count":21,"output_type":"execute_result","data":{"text/plain":"/kaggle/working/directory.zip","text/html":"<a href='directory.zip' target='_blank'>directory.zip</a><br>"},"metadata":{}}]},{"cell_type":"markdown","source":"### I've made further processing on those image using Roboflow","metadata":{}},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}